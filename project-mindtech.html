<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="MindTech - Diffusion-based audio generation using spectrogram representations">
  <title>MindTech - Manuel Alvarez</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css">
</head>
<body>
  <header class="site-header">
    <div class="header-inner">
      <a href="index.html" class="logo">Manuel Alvarez</a>
      <nav class="main-nav">
        <a href="index.html" class="active">Work</a>
        <a href="about.html">About</a>
        <a href="mailto:manuelalvarezml.dev@gmail.com">Contact</a>
      </nav>
      <button class="mobile-menu-toggle" aria-label="Toggle menu">
        <span></span><span></span><span></span>
      </button>
    </div>
  </header>
  <div class="mobile-nav">
    <nav>
      <a href="index.html" class="active">Work</a>
      <a href="about.html">About</a>
      <a href="mailto:manuelalvarezml.dev@gmail.com">Contact</a>
    </nav>
  </div>

  <main class="project-detail" style="margin-top: var(--header-height);">
    <a href="index.html" class="back-link">
      <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M19 12H5M12 19l-7-7 7-7"/></svg>
      Back to Work
    </a>
    <header class="project-detail-header">
      <p class="category">AI & Machine Learning</p>
      <h1>MindTech</h1>
      <p class="subtitle">Diffusion-Based Audio Generation</p>
      <div class="project-meta">
        <span>AI Engineer</span>
        <span>2025</span>
        <span>Wilmington, DE (Remote)</span>
      </div>
    </header>
    <div class="project-detail-content">
      <h2>Overview</h2>
      <p>At MindTech, I worked on adapting diffusion models to audio synthesis using spectrogram representations. I contributed to training diffusion models from scratch on licensed music data and studied how preprocessing, conditioning strategies, and architectural choices affect musical coherence.</p>
      <p>A key part of my work involved identifying the limits of treating audio as images and exploring ways to introduce more explicit musical structure into the generation process.</p>
      <h2>Key Contributions</h2>
      <ul>
        <li>Trained diffusion models on spectrogram representations of audio</li>
        <li>Developed preprocessing tools for normalization and prompt filtering</li>
        <li>Analyzed time-frequency resolution, phase reconstruction, and controllability</li>
        <li>Investigated hybrid symbolic and neural approaches to sound generation</li>
      </ul>
      <h2>Technologies</h2>
      <div class="tech-list">
        <span class="tech-tag">Python</span>
        <span class="tech-tag">Stable Diffusion</span>
        <span class="tech-tag">PyTorch</span>
        <span class="tech-tag">Spectrograms</span>
        <span class="tech-tag">Audio Processing</span>
      </div>
    </div>
  </main>

  <footer class="site-footer">
    <div class="footer-inner">
      <div class="footer-social">
        <a href="https://linkedin.com/in/manuelalvarez" target="_blank" rel="noopener">LinkedIn</a>
        <a href="https://github.com/manuelalvarez" target="_blank" rel="noopener">GitHub</a>
        <a href="https://open.spotify.com/artist/nash-equilibrium" target="_blank" rel="noopener">Spotify</a>
      </div>
      <p class="footer-copyright">&copy; 2024 Manuel Alvarez. Lima, Peru.</p>
    </div>
  </footer>
  <script src="js/main.js"></script>
</body>
</html>
